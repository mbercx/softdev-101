{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"\u2139\ufe0f Introduction","text":"<p>The purpose of this workshop is to learn some basic concepts/tools of software development, with a focus on Python.</p> <ul> <li>\u23f0 When: 11 November 2025 1pm\u20133pm AEST</li> <li>\ud83c\udf0e Where: Room 06-407, Physics building, University of Queensland, Bribane, Australia</li> <li>\ud83d\udc65\u00a0Who:\u00a0Anyone using Python for research/data work</li> <li>\ud83d\udd17\u00a0Registration link: https://forms.gle/7b2vd3KyuK633bPK8</li> </ul> <p>Topics that will be covered (should be executed in order!):</p> <ul> <li>Version control with <code>git</code></li> <li>Python environments</li> <li>Packages</li> <li>Writing documentation</li> <li>Testing with <code>pytest</code></li> <li>Formatting/linting your code with Ruff</li> <li>Continuous Integration (CI)</li> <li>Publishing your code on the PyPI (CD)</li> </ul> <p>Note that although we'll be focussing on tools for Python, this is not a Python course! You won't need any advanced Python concepts, but understanding basic syntax will be helpful.</p> <p>Warning</p> <p>Although we will focus on the basics, there is still a lot of ground to cover. Don't worry in case you don't understand everything right away! All of this is very intimidating at first, I know, I've been there. It took me a long time to learn how to use these tools, and I'm still learning more every day.</p> <p>Have questions? Feedback?</p> <p>During the workshop you can of course raise your hand and ask me, but I may be busy. I've set up a GitHub Discussions page where you can ask questions and give feedback. Don't hesitate to raise your questions there, even after the workshop is finished!</p>"},{"location":"ci/","title":"Continuous Integration","text":""},{"location":"ci/#what","title":"What","text":"<p>Continuous Integration (CI) is the practice of automatically building, testing, and validating your code every time you make changes. Instead of manually running tests or checks before merging code, CI systems do this automatically.</p>"},{"location":"ci/#why","title":"Why","text":"<p>In a sense, a good software developer is lazy. They dislike manual work, and want to automate as much as possible. CI allows you to stop doing all the checks/steps for every code change manually. The added benefit is that this is much less error prone: e.g. your documentation will never be out of date because you forgot to deploy it.</p> <p>Real-world scenario</p> <p>You're maintaining a Python package, and someone wants to make a change to your code. Without CI, you'll have to test their changes locally: did they install/run the <code>pre-commit</code>? Are the tests passing for the Python versions you support? Let's be real: ain't nobody got time for that!</p>"},{"location":"ci/#how","title":"How","text":"<p>GitHub Actions is a CI/CD (Continuous Integration/Continuous Deployment) platform built into GitHub. It lets you define workflows that run automatically in response to events like pushing code, opening pull requests, or adding a release tag.</p> <p>A GitHub actions workflow is defined in a YAML file, stored in the <code>.github/workflows</code> directory.</p>"},{"location":"ci/#example-deploying-documentation","title":"Example: Deploying documentation","text":"<p>Let's have a look at <code>deploy-mkdocs.yaml</code>:</p> <pre><code>name: Deploy MkDocs site to Github pages\non:\n  push:\n    branches:\n      - main\n\npermissions:\n  contents: write\n\njobs:\n  deploy:\n    runs-on: ubuntu-latest\n    steps:\n      - uses: actions/checkout@v4\n      - uses: actions/setup-python@v5\n        with:\n          python-version: 3.x\n      - run: pip install mkdocs mkdocs-material\n      - run: mkdocs gh-deploy --force\n</code></pre> <p>Breaking it down:</p> <ul> <li><code>name</code>: A descriptive name for the workflow that appears in the GitHub Actions UI.</li> <li><code>on</code>: Defines when the workflow runs - here, on every push to the <code>main</code> branch.</li> <li><code>permissions</code>: Grants write access to repository contents (needed to push to the <code>gh-pages</code> branch).</li> <li><code>jobs</code>: Contains one or more jobs to run.   Here we have a single <code>deploy</code> job.</li> <li><code>runs-on</code>: Specifies the operating system for the job (ubuntu-latest).</li> <li><code>steps</code>: A list of sequential actions to perform:</li> <li><code>actions/checkout@v4</code>: Checks out your repository code.</li> <li><code>actions/setup-python@v5</code>: Installs Python (version 3.x means latest 3.x release).</li> <li><code>run</code>: Executes shell commands - first installing dependencies, then deploying docs.</li> </ul> <p>This workflow automatically rebuilds and deploys your documentation site every time you push to main!</p>"},{"location":"ci/#viewing-workflow-runs","title":"Viewing workflow runs","text":"<p>Once you push code to GitHub, you can view workflow runs in the Actions tab of your repository. Each workflow run shows:</p> <ul> <li>Whether it passed or failed.</li> <li>The output of each step.</li> <li>How long each step took.</li> </ul> <p>If a workflow fails, you can click into it to see which step failed and read the error messages to debug the issue.</p> <p>Check your actions!</p> <p>Learning how to write GitHub actions can be a tutorial in itself. For now, go to your repository on GitHub, and click on the Actions tab. Explore the various actions that ran, and see what you can understand.</p>"},{"location":"documentation/","title":"Documentation","text":""},{"location":"documentation/#what","title":"What","text":"<p>Documentation is written material that explains what your code does, how to use it, and why design decisions were made.</p>"},{"location":"documentation/#why","title":"Why","text":"<p>Documentation serves multiple audiences and purposes:</p> <p>For yourself: You'll be surprised how quickly you forget how your own code works. Documentation serves as a reference when you return to a project after weeks or months.</p> <p>For users: Clear documentation helps people understand how to install and use your code without having to read the implementation. Good examples and tutorials lower the barrier to entry.</p> <p>For developers: Documentation explains the \"why\" behind design decisions, making it easier for others (and future you) to understand the codebase and contribute effectively.</p> <p>For discoverability: Well-documented projects are more likely to be found, used, and contributed to. A good README can be the difference between a project being adopted or ignored.</p> <p>Real-world scenario</p> <p>You've written a useful Python package six months ago. A colleague wants to use it, but there's no documentation. They ask you \"How do I install this? What does function X do? Why did you structure it this way?\" You realize you can't remember the answers without digging through the code yourself.</p> <p>With documentation, your colleague can find answers independently, and you can focus on new work instead of repeatedly explaining the same concepts.</p>"},{"location":"documentation/#how","title":"How","text":"<p>For this workshop, we'll focus on creating user-facing documentation using MkDocs, a static site generator that creates beautiful documentation from Markdown files.</p>"},{"location":"documentation/#setting-up-mkdocs","title":"Setting up MkDocs","text":"<p>MkDocs is already set up in the <code>dev-tutorial</code> package. Let's look at the key components:</p> <p>The <code>mkdocs.yml</code> configuration file:</p> <pre><code>site_name: Basics of software development\n\ntheme:\n  name: material\n  features:\n    - navigation.expand\n    - content.code.copy\n\nmarkdown_extensions:\n  - admonition\n  - pymdownx.superfences\n  - pymdownx.tabbed:\n      alternate_style: true\n</code></pre> <p>Key elements:</p> <ul> <li><code>site_name</code>: The title of your documentation site.</li> <li><code>theme</code>: We use Material for MkDocs, a popular, clean theme.</li> <li><code>features</code>: Enable specific functionality (expandable navigation, code copy buttons).</li> <li><code>markdown_extensions</code>: Add support for admonitions, code blocks, tabs, etc.</li> </ul>"},{"location":"documentation/#building-the-documentation","title":"Building the documentation","text":"<p>To build the documentation, we need to run <code>mkdocs</code>, and also have the <code>mkdocs-material</code> theme installed. These are both Python packages, so you could install them manually via <code>pip</code>. However, the convention is to list all required \"devops\" (development operations) packages as extras or \"optional dependencies\": </p> <pre><code>[project.optional-dependencies]\ndocs = [\n  \"mkdocs\",\n  \"mkdocs-material\"\n]\n</code></pre> <p>For the documentation packages, you have to install the <code>docs</code> extra:</p> <pre><code>pip install -e .[docs]\n</code></pre> <p>Be sure that you are in your package directory!</p> <p>Note again that we targeted the current directory (<code>.</code>). Make sure that you are actually at the root of your package directory, also for the commands below.</p> <p>Notice the <code>[docs]</code> at the end: this tells <code>pip</code> to also install the optional dependencies specified under <code>docs</code>. The output is a little bigger this time! We only installed <code>mkdocs</code> and <code>mkdocs-material</code>, but they have their own dependencies.</p> <p>Now we can use the <code>mkdocs</code> command to build the documentation:</p> <pre><code>mkdocs build\n</code></pre> <pre><code>INFO    -  Cleaning site directory\nINFO    -  Building documentation to directory: /path/to/your/dir/dev-tutorial/site\nINFO    -  Documentation built in 0.22 seconds\n</code></pre> <p>Again: this command needs to be executed at the root level of your package, where <code>mkdocs.yml</code> is located. As the second <code>INFO</code> message indicates, the website is built in the <code>site</code> directory. Open it and have a look:</p> macOSLinuxWindows <pre><code>open site/index.html\n</code></pre> <pre><code>xdg-open site/index.html\n</code></pre> <pre><code>start site/index.html\n</code></pre> <p>It's a little empty at the moment, but you can work on that later!</p> <p>Building the documentation and reloading the page every time is rather tedious. Fortunately, you can also \"serve\" the documentation:</p> <pre><code>mkdocs serve\n</code></pre> <p>this will run a server that automatically detects file changes when you save them, and updates the build.</p>"},{"location":"documentation/#writing-documentation","title":"Writing documentation","text":"<p>Documentation files go in the <code>docs/</code> directory as Markdown (<code>.md</code>) files. The landing page of your documentation is <code>docs/index.md</code>. Open the Markdown file and write some content, then save the file.</p> <p>MkDocs uses standard Markdown syntax. For example, to create a link:</p> <pre><code>[link text](https://example.com)\n</code></pre> <p>this will render: link text.</p> <p>MkDocs Material also supports admonitions via the <code>admonition</code> extension. These are highlighted boxes that make important information stand out:</p> <pre><code>!!!warning \"Important\"\n    This is a note that stands out from the main text.\n    You can include code, lists, and other Markdown inside!\n</code></pre> <p>this will render:</p> <p>Important</p> <p>This is a note that stands out from the main text. You can include code, lists, and other Markdown inside!</p> <p>If you're not familiar with Markdown, try this 10 minute tutorial. For the Material for MkDocs theme and all its possible extensions, we refer to their documentation.</p> <p>Give it a try!</p> <p>Serve the documentation with <code>mkdocs serve</code>, open <code>docs/index.md</code>, make some changes and save the file. Can you see the page being updated?</p>"},{"location":"documentation/#deploying-to-github-pages","title":"Deploying to GitHub Pages","text":"<p>GitHub Pages is a free hosting service for static websites, perfect for documentation. MkDocs makes deploying to GitHub Pages incredibly simple.</p> <p>First, shut down the server and make sure your documentation builds successfully:</p> <pre><code>mkdocs build\n</code></pre> <p>Then deploy with a single command:</p> <pre><code>mkdocs gh-deploy --force\n</code></pre> <p>This command:</p> <ol> <li>Builds your documentation to the <code>site/</code> directory</li> <li>Creates (or updates) a <code>gh-pages</code> branch in your repository</li> <li>Pushes the built site to that branch</li> <li>GitHub automatically serves the content from the <code>gh-pages</code> branch</li> </ol> <p>Why use the <code>--force</code>?</p> <p>By using <code>--force</code>, we override the existing <code>gh-pages</code> branch that is already there. The reason it is there is because we already deployed our documentation via continuous integration. You'll learn all about that in the corresponding topic page.</p> <p>Your documentation will be available at:</p> <pre><code>https://&lt;YOUR_USERNAME&gt;.github.io/dev-tutorial-&lt;YOUR_USERNAME&gt;/\n</code></pre> <p>For example, this documentation is hosted at: https://mbercx.github.io/softdev-101/</p> My page is not deploying! \ud83d\ude2d <p>The first time you deploy, you may need to enable GitHub Pages in your repository settings:</p> <ol> <li>Go to your repository on GitHub</li> <li>Click Settings \u2192 Pages</li> <li>Under \"Source\", select the <code>gh-pages</code> branch</li> <li>Click Save</li> </ol> <p>After a few minutes, your documentation should be live!</p> <p>Be careful with <code>gh-deploy</code></p> <p>The <code>gh-deploy</code> command force-pushes to the <code>gh-pages</code> branch, overwriting its history. This is usually fine since the <code>gh-pages</code> branch only contains built documentation, not source code. However, make sure you're in the right repository before deploying!</p> <p>Your documentation is looking great! But how do you know your code actually works as expected? Let's add some automated testing to verify everything behaves correctly. Next up: Testing with pytest</p>"},{"location":"environments/","title":"Python environments","text":""},{"location":"environments/#what","title":"What","text":"<p>A Python virtual environment is an isolated workspace that contains a specific Python interpreter (binary) along with its own set of installed packages and dependencies. Each environment is isolated, meaning packages installed in one environment don't affect others.</p>"},{"location":"environments/#why","title":"Why","text":"<p>The main reason to use virtual environments is to avoid dependency conflicts: different projects often require different versions of the same package.</p> <p>Real-world scenario</p> <p>Imagine you're maintaining two projects: Project A requires <code>numpy==1.19.0</code> and Project B needs <code>numpy==1.24.0</code>. Without environments, you'd have to constantly uninstall and reinstall numpy when switching between projects. With environments, each project has its own isolated numpy version, and switching is seamless.</p> <p>Typically, you want to avoid installing anything within your \"global\"/\"system\" environment. Cleaning this up is much more involved than simply deleting a virtual environment and starting over.</p>"},{"location":"environments/#how","title":"How","text":""},{"location":"environments/#creating-environments","title":"Creating environments","text":"<p>There many tools out there for creating and managing environments in Python (arguably too many). For this workshop, we'll use the <code>venv</code> module, which is part of the standard library. The main reason is that it's instructive: it's easier to understand how environments work, and many other tools are built on top of <code>venv</code>.</p> <p>A very useful command in figuring out the Python interpreter/instance/binary you are working with is <code>which</code>:</p> macOS/LinuxWindows <pre><code>which python3\n</code></pre> <pre><code>where python3\n</code></pre> <p>This will point to the first Python binary in your <code>PATH</code>. If you are not working in a virtual environment, this will typically be your system Python instance. For example, in my case the command returns</p> <pre><code>/usr/bin/python3\n</code></pre> <p>Let's create a new virtual environment! If you are still in your <code>test-repo</code> directory, navigate up one level to get back to your <code>softdev-workshop</code> directory:</p> <pre><code>cd ..\npwd\n</code></pre> <pre><code>/path/to/your/softdev-workshop\n</code></pre> <p>The <code>venv</code> module can be run as a script using the <code>-m</code> option. To create a virtual environment in the <code>.my_env</code> directory, run:</p> <pre><code>python3 -m venv .my_env\n</code></pre> <p>Info</p> <p>Running the <code>venv</code> module with <code>-m</code>, it behaves much like any command line tool. To see its usage, run:</p> <pre><code>python3 -m venv --help\n</code></pre> <p>Time to activate the virtual environment!</p> <code>bash</code>/<code>zsh</code><code>fish</code>Windows (cmd)Windows (PowerShell) <pre><code>source .my_env/bin/activate\n</code></pre> <pre><code>source .my_env/bin/activate.fish\n</code></pre> <pre><code>.my_env\\Scripts\\activate.bat\n</code></pre> <pre><code>.my_env\\Scripts\\Activate.ps1\n</code></pre> <p>Typically, your prompt will be adapted, adding <code>(.my_env)</code> somewhere to indicate you are working \"inside the <code>.my_env</code> environment\". To verify this, let's see what Python instance we're working with:</p> macOS/LinuxWindows <pre><code>which python3\n</code></pre> <pre><code>where python3\n</code></pre> <p>This should now return a path inside the <code>bin</code> subdirectory of the virtual environment directory:</p> <pre><code>/path/to/your/softdev-workshop/.my_env/bin/python3\n</code></pre>"},{"location":"environments/#installing-packages","title":"Installing packages","text":"<p>We've created and activated our virtual environment, but how do we install packages in it? For this workshop, we'll use <code>pip</code>, which is installed by default in every virtual environment created with <code>venv</code>. Let's first make sure we are working with the <code>pip</code> binary from our virtual environment:</p> macOS/LinuxWindows <pre><code>which pip\n</code></pre> <pre><code>where pip\n</code></pre> <p>Which should once again return a path within your environment directory:</p> <pre><code>/path/to/your/dir/.my_env/bin/pip\n</code></pre> <p>Important</p> <p>If the command above does not return the <code>pip</code> binary corresponding to your environment, you will not be installing packages in it when using <code>pip install</code>! Make sure you have activated your environment as per the instructions above.</p> <p>Let's install our first package!</p> <pre><code>pip install cowsay\n</code></pre> <p>If all goes well, you should see that v6.1 of the package is successfully installed: </p> <pre><code>Collecting cowsay\n  Downloading cowsay-6.1-py3-none-any.whl (25 kB)\nInstalling collected packages: cowsay\nSuccessfully installed cowsay-6.1\n</code></pre> Wait, I'm getting a WARNING! <p>You likely will get a warning regarding your <code>pip</code> version being outdated:</p> <pre><code>WARNING: You are using pip version 21.2.4; however, version 25.3 is available.\nYou should consider upgrading via the '/path/to/your/dir/.my_env/bin/python3 -m pip install --upgrade pip' command.\n</code></pre> <p>For the material in this workshop, you need at least <code>pip&gt;=21.3</code>. If the reported <code>pip</code> version is older, follow the instructions to upgrade it.</p> <p>Let's have the cow spit some facts:</p> <pre><code>cowsay -t \"Python is awesome!\"\n</code></pre> <p>As you can see, the <code>cowsay</code> package ships a cute little command-line interface (CLI) with its installation. Try finding the location of this command again.</p> <p>Finally, let's look at the <code>list</code> of packages we have installed in our virtual environment:</p> <pre><code>pip list\n</code></pre> <pre><code>Package    Version\n---------- -------\ncowsay     6.1\npip        25.3\nsetuptools 58.0.4\n</code></pre> <p>As mentioned, <code>pip</code> is automatically installed in every virtual environment created with <code>venv</code>, whereas <code>cowsay</code> we installed afterwards with <code>pip</code>. Finally, <code>setuptools</code> is a package that helps you build and distribute Python packages, but we don't need to go into that here.</p> <p>A PEP a day keeps the doctor away</p> <p>Can't get enough of virtual environments? Read the original Python Enhancement Proposal (PEP) that introduced them into the standard library: PEP 405.</p> <p>With your environment set up and ready to install packages, it's time to learn how to structure your own Python code as a package. Next up: Packages</p>"},{"location":"formatting/","title":"Formatting &amp; Linting","text":""},{"location":"formatting/#what","title":"What","text":"<p>Code formatting refers to the consistent styling of your code - how it looks visually. This includes indentation, spacing, line length, quote styles, and other stylistic choices that don't affect how the code runs but impact how it reads.</p> <p>Linting checks your code for potential bugs, code smells, and programming errors. It catches issues like unused variables, undefined names, or overly complex code before they cause problems.</p>"},{"location":"formatting/#why","title":"Why","text":"<p>Formatting helps you focus on logic rather than style:</p> <ul> <li>Save time and energy: No more deciding where to put spaces or how to break lines</li> <li>Improved readability: Consistent code is easier to read and understand</li> <li>Better collaboration: Everyone's code looks the same, so git diffs show real changes instead of whitespace adjustments</li> </ul> <p>Linting catches bugs before they happen:</p> <ul> <li>Early bug detection: Find issues like unused variables or undefined names before running your code</li> <li>Code quality: Identify overly complex code, missing error handling, or potential performance issues</li> <li>Learn best practices: Linters teach you Python conventions and common pitfalls to avoid</li> </ul> <p>Real-world scenario</p> <p>You're collaborating with two colleagues on a data analysis project. One person uses tabs for indentation, another uses 2 spaces, and you use 4 spaces. One person puts spaces around operators (<code>x = 1 + 2</code>), another doesn't (<code>x=1+2</code>).</p> <p>Every time you work on the same file, version control shows dozens of \"changes\" that are just formatting differences. Code reviews become debates about style instead of correctness.</p> <p>With a formatter like <code>black</code> or <code>ruff</code>, everyone runs the formatter before committing. All code looks identical regardless of who wrote it, git diffs only show meaningful changes, and you can focus on solving problems instead of arguing about spaces.</p>"},{"location":"formatting/#how","title":"How","text":"<p>We'll use <code>ruff</code> as our tool of choice. It's fast, modern, and can handle both formatting (using <code>black</code> under the hood) and linting. Let's install <code>ruff</code> in our environment:</p> <pre><code>pip install ruff\n</code></pre> <p>Let's see <code>ruff</code> in action! Have a look at the file <code>src/dev_tutorial_&lt;YOUR_USERNAME&gt;/messy.py</code>:</p> <pre><code># src/dev_tutorial_&lt;YOUR_USERNAME&gt;/messy.py\ndef calculate_statistics(data,include_median=True):\n    \"\"\"Calculate statistics for a list of numbers.\"\"\"\n    debug_mode=True\n    if len(data)==0:\n        return None\n\n    mean=sum(data)/len(data)\n    result={'mean':mean,'min':min(data),'max':max(data)}\n\n    if include_median:\n        sorted_data=sorted(data)\n        n=len(sorted_data)\n        median=sorted_data[n//2] if n%2!=0 else (sorted_data[n//2-1]+sorted_data[n//2])/2\n        result['median']=median\n\n    return result\n</code></pre> <p>This code has several formatting issues:</p> <ul> <li>Missing spaces after commas in function parameters</li> <li>Inconsistent spacing around operators (<code>==</code>, <code>=</code>, <code>/</code>, <code>%</code>, <code>//</code>)</li> <li>No spaces around dictionary keys and values</li> </ul> <p>Now run the formatter:</p> <pre><code>ruff format\n</code></pre> <pre><code>1 file reformatted,  5 files left unchanged\n</code></pre> <p>Open <code>src/dev_tutorial_&lt;YOUR_USERNAME&gt;/messy.py</code> again and check how the code has changed. <code>ruff</code> has automatically fixed all the formatting issues:</p> <pre><code>def calculate_statistics(data, include_median=True):\n    \"\"\"Calculate statistics for a list of numbers.\"\"\"\n    debug_mode = True\n    if len(data) == 0:\n        return None\n\n    mean = sum(data) / len(data)\n    result = {\"mean\": mean, \"min\": min(data), \"max\": max(data)}\n\n    if include_median:\n        sorted_data = sorted(data)\n        n = len(sorted_data)\n        median = (\n            sorted_data[n // 2]\n            if n % 2 != 0\n            else (sorted_data[n // 2 - 1] + sorted_data[n // 2]) / 2\n        )\n        result[\"median\"] = median\n\n    return result\n</code></pre> <p>Much better! But we still haven't checked the code for quality issues. Let's run the linter:</p> <pre><code>ruff check\n</code></pre> <pre><code>F841 Local variable `debug_mode` is assigned to but never used\n --&gt; src/dev_tutorial_&lt;YOUR_USERNAME&gt;/messy.py:3:5\n  |\n1 | def calculate_statistics(data, include_median=True):\n2 |     \"\"\"Calculate statistics for a list of numbers.\"\"\"\n3 |     debug_mode = True\n  |     ^^^^^^^^^^\n4 |     if len(data) == 0:\n5 |         return None\n  |\nhelp: Remove assignment to unused variable `debug_mode`\n\nFound 1 error.\nNo fixes available (1 hidden fix can be enabled with the `--unsafe-fixes` option).\n</code></pre> <p>The linter found an issue with our code! To understand the problem, run:</p> <pre><code>ruff rule F841\n</code></pre> <p>Now fix the issue by removing the unused <code>debug_mode</code> variable After making these changes manually, run both commands again to verify everything is clean:</p> <pre><code>ruff format &amp;&amp; ruff check\n</code></pre> <pre><code>6 files left unchanged\nAll checks passed!\n</code></pre>"},{"location":"formatting/#automating-with-pre-commit","title":"Automating with pre-commit","text":"<p>Instead of remembering to run <code>ruff format</code> and <code>ruff check</code> before every commit, you can use <code>pre-commit</code> to automatically run these checks.</p> <p><code>pre-commit</code> is a framework that manages git hooks - scripts that run automatically before you commit code.</p> <p>First, install pre-commit:</p> <pre><code>pip install pre-commit\n</code></pre> <p>The project already has a <code>.pre-commit-config.yaml</code> file that configures which checks to run (have a look!). To install the git hooks, run:</p> <pre><code>pre-commit install\n</code></pre> <p>Now, every time you try to commit code, <code>pre-commit</code> will automatically:</p> <ol> <li>Run <code>ruff format</code> to format your code</li> <li>Run <code>ruff check</code> to lint your code</li> <li>If any issues are found, the commit will be blocked until you fix them</li> </ol> <p>You can also run the checks manually without committing:</p> <pre><code>pre-commit run -a\n</code></pre> <p>This ensures your code is always formatted and linted before it enters version control!</p> <p>Give it a try!</p> <p>Try to make some changes to one of the modules, and run <code>git commit</code>. Both the linter and formatter should run automatically.</p> <p>You've set up local tools to build &amp; deploy documentation, run tests and check your code. Wouldn't it be nice if all this ran automatically every time you push to GitHub? That's where Continuous Integration comes in! Next up: Continuous Integration (CI)</p>"},{"location":"glossary/","title":"\ud83d\udcdc Glossary","text":"<p>Note</p> <p>This page mainly discusses \"semantics\": i.e. what do we mean when we say words? These definitions are my own, and are by no means perfect. But hopefully they help you understand the content of this material better!</p> <ul> <li>version control system (VCS): a tool that records changes to a file or set of files over time so that you can recall specific versions later.</li> <li>repository: A directory tracked by <code>git</code> that stores all your project files along with the complete history of every change made to them.</li> <li>commit: A snapshot of your project at a specific point in time, recording what changes were made, who made them, and when. Each commit has a unique identifier and typically includes a message describing the changes.</li> <li>branch: An independent line of development in a git repository that allows you to work on features or fixes in isolation from the main codebase. Branches can be merged back together later.</li> <li>remote: A <code>git</code> repository hosted on a server (typically GitHub) that you can push changes to and pull changes from, enabling collaboration with others.</li> <li>fork: A personal copy of someone else's repository that you can modify independently and optionally contribute changes back to the original.</li> <li>virtual environment: An isolated Python workspace containing its own interpreter and packages, isolated from other environments and the system Python installation.</li> <li>dependency: A package or library that your code requires to function properly. Dependencies can have their own dependencies (transitive dependencies).</li> <li>package: A collection of Python modules that can be installed and imported. Packages are distributed through repositories like PyPI and installed using tools like <code>pip</code>.</li> <li>pip: <code>pip</code> installs packages! Python's package installer, used to install, upgrade, and manage packages from the Python Package Index (PyPI) and other sources.</li> <li>standard library: The collection of modules that come with Python by default and can be imported without additional installation (e.g., <code>os</code>, <code>sys</code>, <code>json</code>, <code>datetime</code>).</li> <li>built-in: A function, type, or feature that's available in Python without importing anything (e.g., <code>print()</code>, <code>len()</code>, <code>list</code>). These are always available.</li> <li>clone: Creating a local copy of a remote repository on your computer, including all its files, history, and branches.</li> <li>staging area: An intermediate space in git where you prepare changes before committing them. Also called the \"index\".</li> <li>merge: Combining changes from one branch into another, integrating the development histories of both branches.</li> <li>pull request (PR): A request to merge changes from one branch into another, typically used for code review and collaboration on platforms like GitHub.</li> <li>HEAD: A pointer in git that refers to the current branch or commit you're working on.</li> <li>module: A Python file containing definitions and statements that can be imported and used in other Python programs.</li> <li>import: A Python statement that brings code from other modules or packages into your current program's namespace.</li> <li>IDE (Integrated Development Environment): A software application that combines a code editor, debugger, and other development tools in one interface (e.g., VS Code, PyCharm).</li> <li>debugging: The process of finding and fixing errors (bugs) in code, often using tools that allow you to pause execution and inspect variables.</li> <li>REPL (Read-Eval-Print Loop): An interactive programming environment that reads user input, evaluates it, prints the result, and loops back. Python's interactive shell is a REPL.</li> <li>CI/CD (Continuous Integration/Continuous Deployment): Automated processes that build, test, and deploy code changes, ensuring that software is always in a releasable state.</li> <li>refactoring: Restructuring existing code to improve its readability, maintainability, or performance without changing its external behavior.</li> <li>semantic versioning: A versioning scheme using three numbers (MAJOR.MINOR.PATCH) to communicate the nature of changes in software releases (e.g., 1.2.3).</li> </ul>"},{"location":"packages/","title":"Packages","text":""},{"location":"packages/#what","title":"What","text":"<p>A Python package is a collection of modules (Python files) organized in a directory structure that can be imported and distributed. At its simplest, a package is just a directory containing Python files and a special <code>__init__.py</code> file that marks it as a package.</p> <p>The basic structure looks like this:</p> <pre><code>mypackage/\n\u251c\u2500\u2500 __init__.py\n\u251c\u2500\u2500 module1.py\n\u2514\u2500\u2500 module2.py\n</code></pre>"},{"location":"packages/#why","title":"Why","text":"<p>Packages serve several important purposes:</p> <p>Organization: As your code grows beyond a single file, packages help you organize related functionality into logical groups. Instead of one massive <code>utils.py</code> file, you might have <code>mypackage/strings.py</code>, <code>mypackage/numbers.py</code>, etc.</p> <p>Reusability: Proper package structure makes it easy to reuse your code across different projects. Once packaged, you can install your code with <code>pip install mypackage</code> just like any other library.</p> <p>Distribution: A well-structured package can be shared with others via PyPI (Python Package Index), GitHub, or private repositories. This is how all the packages you <code>pip install</code> are organized.</p> <p>Real-world scenario</p> <p>You've written some useful data processing functions for one project. Later, you need the same functions in a different project. Without proper packaging, you'd copy-paste the files and manually track dependencies. With a package, you simply <code>pip install</code> it in the new project and import what you need.</p>"},{"location":"packages/#how","title":"How","text":""},{"location":"packages/#workshop-repository","title":"Workshop repository","text":"<p>For the rest of this workshop, you'll need to have a <code>git</code>-tracked Python package to work on. Create a new empty repository on GitHub called <code>dev-tutorial-&lt;YOUR_USERNAME&gt;</code> and <code>clone</code> it to your local directory:</p> <pre><code>git clone https://github.com/&lt;YOUR_USERNAME&gt;/dev-tutorial-&lt;YOUR_USERNAME&gt;.git\n</code></pre> <p>Why add GitHub my username to the package name?</p> <p>The main reason is to have a unique package name. This is important when we want to publish our package on the PyPI in the last topics section</p> Can I also work with my own code? <p>Of course! But you may have a bit more work: the instructions in the next pages won't perfectly fit your package. If you get stuck, consider starting from a fresh repository and using the template discussed below.</p> <p>To get the workshop package template, we'll use a tool called <code>copier</code>. First install it in your virtual environment:</p> <pre><code>pip install copier\n</code></pre> <p>Now, enter your package directory:</p> <pre><code>cd dev-tutorial-&lt;YOUR_USERNAME&gt;\n</code></pre> <p>Then <code>copy</code> the workshop template into your fresh repository.</p> <pre><code>copier copy -f https://github.com/mbercx/softdev-101 .\n</code></pre> <p>To make sure Python is aware of the changes we make as we work on our package, let's install it from its local directory in \"editable\" mode (<code>-e</code>):</p> <pre><code>pip install -e .\n</code></pre> <p>Info</p> <p>Note that for both the <code>copier copy</code> and <code>pip install</code> command, we simply targeted the \"local directory\" (<code>.</code>). You can target any directory you like, the reason I wrote the instructions this way is to minimize the number of <code>&lt;YOUR_USERNAME&gt;</code> instructions that you have to adapt manually.</p> <p>Listing the packages installed in our environment again with <code>pip list</code>:</p> <pre><code>Package                Version Editable project location\n---------------------- ------- ---------------------------------------\nannotated-types        0.7.0\ncolorama               0.4.6\ncopier                 9.10.3\ncowsay                 6.1\ndev-tutorial           0.0.1   /Users/mbercx/tmp/workshop/dev-tutorial\n...\n</code></pre> <p>You can see a new column: <code>Editable project location</code>. This is <code>pip</code> telling you that it installed that package from a local directory in editable mode.</p>"},{"location":"packages/#structure","title":"Structure","text":"<p>In principle, you can adopt any package structure you'd like. However, adhering to a standard package structure makes it easier for others to understand and contribute to your code. Everyone knows where to find the source code, tests, and documentation. Have a look at the structure of the <code>dev-tutorial</code> package:</p> Linux/macOSWindows (cmd)Windows (PowerShell) <pre><code>tree .\n</code></pre> <pre><code>tree /F\n</code></pre> <pre><code>tree /F\n</code></pre> <p>Expected structure:</p> <pre><code>\u251c\u2500\u2500 docs\n\u2502\u00a0\u00a0 \u251c\u2500\u2500 developer.md\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 index.md\n\u251c\u2500\u2500 LICENSE\n\u251c\u2500\u2500 mkdocs.yml\n\u251c\u2500\u2500 pyproject.toml\n\u251c\u2500\u2500 README.md\n\u251c\u2500\u2500 src\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 dev_tutorial_mbercx\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 __about__.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 __init__.py\n\u2502\u00a0\u00a0     \u251c\u2500\u2500 functions.py\n\u2502\u00a0\u00a0     \u2514\u2500\u2500 messy_code.py\n\u2514\u2500\u2500 tests\n    \u251c\u2500\u2500 conftest.py\n    \u2514\u2500\u2500 test_functions.py\n</code></pre> The <code>tree</code> command doesn't exist! <p>On Linux/macOS, you may need to install <code>tree</code> (<code>brew install tree</code> on macOS, or <code>apt install tree</code> on Ubuntu). On Windows, <code>tree</code> is built-in but shows output in a different format. The <code>tree</code> command is a neat way to visualize directory structure, but it's not necessary for the tutorial.</p> <p>Let's go over the various directories and files:</p> <ul> <li><code>docs</code>: these contain the documentation files, which you are reading right now!   The <code>mkdocs.yml</code> file is the configuration for the documentation, you'll read all about that in the corresponding topic.</li> <li><code>LICENSE</code>: it's standard practise to ship your code with a license, that tells others how they can use your code.   A very common (and permissive) option is the MIT license.</li> <li><code>pyproject.toml</code>: The modern standard for Python package configuration.   Contains package metadata (name, version, dependencies), build system settings, and tool configurations.</li> <li><code>README.md</code>: The front page of your package - the first thing people see on GitHub or PyPI.</li> <li><code>src/</code>: Contains your actual source code. Using a <code>src/</code> directory is best practice because it keeps the project root clean and prevents import issues during testing.</li> <li><code>src/dev_tutorial_mbercx/</code>: The actual Python package containing the modules.   Note the underscore instead of hyphen - package names must be valid Python identifiers.</li> <li><code>tests/</code>: Your test files, kept separate from source code. We'll cover this in the tests topic.</li> </ul>"},{"location":"packages/#pushing-the-template-files-to-github","title":"Pushing the template files to GitHub","text":"<p>Let's push the local changes in our <code>dev-tutorial</code> package to GitHub. Stage all the new files with:</p> <pre><code>git add .\n</code></pre> <p>And <code>commit</code> them:</p> <pre><code>git commit -m 'Initial commit'\n</code></pre> <p>You'll see the full list of files that have been added in this commit. Time to <code>push</code> your local changes to GitHub:</p> <pre><code>git push origin\n</code></pre> <p><code>origin</code> is the default name of the remote repository you cloned from. To see all the remotes you have configured, use:</p> <pre><code>git remote -v\n</code></pre> <p>You've got your package structure in place! Now let's make it easy for others (and your future self) to understand and use your code. Next up: Writing documentation</p>"},{"location":"publishing/","title":"Publishing","text":""},{"location":"publishing/#what","title":"What","text":"<p>Publishing a Python package means making it available for others to install via <code>pip install</code>. The primary distribution platform is the Python Package Index (PyPI), the official repository where over 500,000 packages are hosted. When you run <code>pip install numpy</code> or <code>pip install pytest</code>, you're installing packages from PyPI.</p>"},{"location":"publishing/#why","title":"Why","text":"<p>Publishing your code serves several important purposes:</p> <p>Ease of installation: Instead of cloning repositories and installing from source, users can simply <code>pip install your-package</code>. This dramatically lowers the barrier to entry for using your code.</p> <p>Dependency management: When your package is on PyPI, other packages can list it as a dependency in their <code>pyproject.toml</code>. This creates a network of packages that work together seamlessly.</p> <p>Versioning and stability: PyPI hosts multiple versions of your package, allowing users to pin to specific versions they know work (<code>your-package==1.2.3</code>) while you continue developing new features.</p> <p>Discoverability: PyPI makes your package searchable and discoverable by the broader Python community, increasing its potential impact and user base.</p> <p>Professional credibility: A well-maintained package on PyPI signals that your code is ready for production use and demonstrates your commitment to software engineering best practices.</p> <p>Real-world scenario</p> <p>You've developed a useful data analysis tool for your research group. Currently, colleagues need to:</p> <ol> <li>Clone your GitHub repository</li> <li>Navigate to the directory</li> <li>Create a virtual environment</li> <li>Run <code>pip install -e .</code></li> <li>Remember to pull updates regularly</li> </ol> <p>After publishing to PyPI, they simply run <code>pip install your-tool</code> and get started immediately. Updates are just <code>pip install --upgrade your-tool</code> away.</p>"},{"location":"publishing/#how","title":"How","text":""},{"location":"publishing/#building-your-package","title":"Building your package","text":"<p>Before you can publish your package, you need to build it into distribution formats that <code>pip</code> can install. The two standard formats are:</p> <ul> <li>Wheel (<code>.whl</code>): A pre-built binary distribution that installs quickly</li> <li>Source distribution (<code>.tar.gz</code>): The raw source code that gets built during installation</li> </ul> <p>To create these distributions, you need a build backend. The workshop template uses Hatchling, a modern, standards-compliant build system. You can see this configured in your <code>pyproject.toml</code>:</p> <pre><code>[build-system]\nrequires = [\"hatchling\"]\nbuild-backend = \"hatchling.build\"\n</code></pre> <p>This tells Python's build tools to use Hatchling when building your package.</p> <p>To build your package, use the <code>build</code> module (part of the Python Packaging Authority's standard tooling):</p> <pre><code>pip install build\npython -m build\n</code></pre> <pre><code>* Creating isolated environment: venv+pip...\n* Installing packages in isolated environment:\n  - hatchling\n* Getting build dependencies for sdist...\n* Building sdist...\n* Building wheel from sdist...\n* Creating isolated environment: venv+pip...\n* Installing packages in isolated environment:\n  - hatchling\n* Getting build dependencies for wheel...\n* Building wheel...\nSuccessfully built dev-tutorial-&lt;YOUR_USERNAME&gt;-0.0.1.tar.gz and dev_tutorial_&lt;YOUR_USERNAME&gt;-0.0.1-py3-none-any.whl\n</code></pre> <p>This creates a <code>dist/</code> directory containing both distribution formats:</p> Linux/macOSWindows <pre><code>ls dist/\n</code></pre> <pre><code>dir dist\\\n</code></pre> <p>Expected output:</p> <pre><code>dev-tutorial-&lt;YOUR_USERNAME&gt;-0.0.1.tar.gz\ndev_tutorial_&lt;YOUR_USERNAME&gt;-0.0.1-py3-none-any.whl\n</code></pre>"},{"location":"publishing/#versioning","title":"Versioning","text":"<p>Notice that the built distributions include a version number (<code>0.0.1</code>). This comes from the <code>__version__</code> variable in <code>src/dev_tutorial_&lt;YOUR_USERNAME&gt;/__about__.py</code>:</p> <pre><code>__version__ = \"0.0.1\"\n</code></pre> <p>Version numbers help users understand what changes between releases. The standard approach is Semantic Versioning (SemVer), which uses the format <code>MAJOR.MINOR.PATCH</code>:</p> <ul> <li>MAJOR: Increment when you make backwards-incompatible API changes (e.g., <code>1.0.0</code> \u2192 <code>2.0.0</code>)</li> <li>MINOR: Increment when you add functionality in a backward-compatible manner (e.g., <code>1.0.0</code> \u2192 <code>1.1.0</code>)</li> <li>PATCH: Increment when you make backward-compatible bug fixes (e.g., <code>1.0.0</code> \u2192 <code>1.0.1</code>)</li> </ul> <p>For example: - <code>0.0.1</code> \u2192 <code>0.0.2</code>: Fixed a bug - <code>0.0.2</code> \u2192 <code>0.1.0</code>: Added a new feature - <code>0.1.0</code> \u2192 <code>1.0.0</code>: First stable release or breaking changes</p> <p>Version 0.x.x</p> <p>Versions starting with <code>0.</code> (like <code>0.1.0</code>) indicate the package is still in early development. Users should expect breaking changes between minor versions. Once your API is stable, release version <code>1.0.0</code>.</p>"},{"location":"publishing/#creating-api-tokens","title":"Creating API tokens","text":"<p>Before you can upload to PyPI or Test PyPI, you need to create an API token for authentication. PyPI no longer accepts username/password authentication - tokens are required.</p> <p>For Test PyPI:</p> <ol> <li>Create an account at https://test.pypi.org/</li> <li>Go to Account Settings \u2192 API tokens</li> <li>Click \"Add API token\"</li> <li>Give it a name (e.g., \"dev-tutorial upload\")</li> <li>Copy the token immediately - it's only shown once!</li> </ol> <p>The token will look like <code>pypi-...</code> (a long string of characters).</p> <p>Save your token!</p> <p>API tokens are only displayed once when created. Store it somewhere safe - you'll need it for uploads. If you lose it, you'll have to create a new one.</p>"},{"location":"publishing/#uploading-to-test-pypi","title":"Uploading to Test PyPI","text":"<p>Before publishing to the real PyPI, it's smart to test with Test PyPI - a separate instance where you can experiment without consequences.</p> <p>Install <code>twine</code>, the tool for uploading packages:</p> <pre><code>pip install twine\n</code></pre> <p>Upload your distributions to Test PyPI:</p> <pre><code>twine upload --repository testpypi dist/*\n</code></pre> <p>When prompted: - Username: Enter <code>__token__</code> (exactly as written, with double underscores) - Password: Paste your API token (including the <code>pypi-</code> prefix)</p> <p>Once uploaded, your package will be available at:</p> <pre><code>https://test.pypi.org/project/dev-tutorial-&lt;YOUR_USERNAME&gt;/\n</code></pre> <p>To install from Test PyPI and verify it works:</p> <pre><code>pip install --index-url https://test.pypi.org/simple/ dev-tutorial-&lt;YOUR_USERNAME&gt;\n</code></pre> <p>The real PyPI</p> <p>Test PyPI is a separate service from the real PyPI. Packages uploaded there are periodically deleted, and dependencies from the real PyPI might not be available. It's purely for testing the upload process! Publishing to the real PyPI is very similar, but I would only do it with your proper package when it's ready.</p>"},{"location":"publishing/#automating-with-github-actions","title":"Automating with GitHub Actions","text":"<p>Manually building and uploading packages works, but it's error-prone and tedious. A better approach is to automate the entire publishing process with GitHub Actions. The workshop template includes a workflow file <code>.github/workflows/cd.yml</code> that automatically publishes to Test PyPI when you push a version tag.</p> <p>If you are feeling lost</p> <p>I know this all seems like a lot. It is! The main goal here is to expose you to this approach of doing things, you can take your time in understanding all the aspects.</p>"},{"location":"publishing/#setting-up-trusted-publishing","title":"Setting up trusted publishing","text":"<p>Instead of storing API tokens as secrets, the workflow uses trusted publishing - a modern, more secure authentication method. With trusted publishing, PyPI trusts GitHub Actions to publish on your behalf without needing to manage tokens.</p> <p>To set this up on Test PyPI:</p> <ol> <li>Go to https://test.pypi.org/ and log in</li> <li>Click Your projects (but you won't have a project yet - that's okay!)</li> <li>Go to Publishing in the left sidebar</li> <li>Scroll to Add a new pending publisher</li> <li>Fill in the form:</li> <li>PyPI Project Name: <code>dev-tutorial-&lt;YOUR_USERNAME&gt;</code> (your package name)</li> <li>Owner: Your GitHub username</li> <li>Repository name: <code>dev-tutorial-&lt;YOUR_USERNAME&gt;</code></li> <li>Workflow name: <code>cd.yml</code></li> <li>Click Add</li> </ol> <p>How trusted publishing works</p> <p>When your GitHub Actions workflow runs, GitHub issues a short-lived identity token that proves the workflow is running from your specific repository. Test PyPI verifies this token and allows the upload - no long-lived secrets needed! This is more secure because there are no tokens to leak or rotate.</p>"},{"location":"publishing/#automated-publishing-workflow","title":"Automated publishing workflow","text":"<p>With trusted publishing and automated workflows, releasing a new version is as simple as:</p> <ol> <li>Update the version in <code>__about__.py</code> following SemVer (e.g., <code>0.0.1</code> \u2192 <code>0.1.0</code>)</li> <li> <p>Commit the bump in version number:</p> <pre><code># Update version, commit, tag, and push\ngit commit -am 'Bump version to 0.1.0'\n</code></pre> </li> <li> <p>Create and push a Git tag:</p> <pre><code>git tag v0.1.0\ngit push origin main v0.1.0\n</code></pre> </li> </ol> <p>\u2192 GitHub Actions automatically builds and publishes to Test PyPI!</p> <p>Watch the workflow run in the Actions tab of your repository. If something goes wrong, check the workflow logs for error messages.</p> <p>Once published, verify your package has a new version at <code>https://test.pypi.org/project/dev-tutorial-&lt;YOUR_USERNAME&gt;/</code>.</p> <p>This is the end...</p> <p>For now, this is the end of this basics of software development workshop. More material might be coming soon!</p>"},{"location":"setup/","title":"\u2699\ufe0f Setup","text":""},{"location":"setup/#before-the-workshop","title":"Before the workshop","text":"<p>To get up and running quickly, please make sure you have the following ready for the workshop:</p> <ol> <li>Bring a laptop!</li> <li>A working Python binary for your OS, version 3.9 or above.    You can find a guide for various operating systems here.</li> <li>A GitHub account.</li> <li>Have <code>git</code> installed on your system.</li> <li>A code editor.    My preferred option is VSCode.</li> </ol>"},{"location":"setup/#github-authentication","title":"GitHub authentication","text":"<p>For some parts of the workshop, you'll need to be able to authenticate to GitHub from the terminal. If you don't know how to do this, the easiest is to use a token:</p> <ol> <li>Go to GitHub \u2192 Click on your profile avatar (top right) \u2192 Settings \u2192 Developer settings (bottom) \u2192 Personal access tokens \u2192 Tokens (classic).</li> <li>Click \"Generate new token\" \u2192 \"Generate new token (classic)\".</li> <li>Give it a description in the \"Note\" (e.g., \"Software development workshop\").</li> <li>Select scopes: check both \"repo\" and \"workflow\".</li> <li>Click \"Generate token\" at the bottom and copy the token.</li> </ol> <p>Whenever you need to authenticate to GitHub (e.g. when you <code>push</code> to your remote), you can use this token as your password.</p> <p>Warning</p> <p>Be sure to copy and save the token somewhere safe!</p>"},{"location":"setup/#workshop-directory","title":"Workshop directory","text":"<p>To keep things nice and organised, it's best if you create a single directory where you execute all the commands for the workshop. Navigate to a suitable parent folder, and make a new directory:</p> <pre><code>mkdir softdev-workshop\ncd softdev-workshop\n</code></pre> <p>Operating System</p> <p>You can use your preferred operating system, but I have no experience with Windows. If you are using Windows, it may be a good idea to install WSL. I'll try to also show the Windows Powershell equivalent of each command, but these don't always exist, and I may forget some here and there.</p>"},{"location":"tests/","title":"Tests","text":""},{"location":"tests/#what","title":"What","text":"<p>Tests are code that verifies your source code works as expected. They automatically check that functions produce correct outputs for given inputs, handle edge cases properly, and behave correctly when things go wrong.</p> <p>Common types of tests include:</p> <ul> <li>Unit tests: Test individual functions or methods in isolation.</li> <li>Integration tests: Test how different parts of your code work together.</li> <li>Regression tests: Ensure bugs that were fixed don't come back.</li> </ul>"},{"location":"tests/#why","title":"Why","text":"<p>Testing serves several critical purposes:</p> <p>Carefree development: With good tests, you can confidently change your code knowing that if you break something, the tests will catch it.</p> <p>Catch bugs early: Tests help you find problems before your code reaches users (or before your paper is published). It's much cheaper to fix a bug during development than after deployment.</p> <p>Prevent regressions: Once you fix a bug, write a test for it. This ensures the same bug doesn't sneak back in during future changes.</p> <p>Real-world scenario</p> <p>You've written a Python script to analyze experimental data for your research. It works correctly but takes 30 minutes to run, so you want to make it faster.</p> <p>You manage to make it run in 3 minutes - great! But how do you know it still produces the same results?</p> <p>Without tests, you'd need to manually compare outputs, check figures visually, and hope you didn't introduce subtle bugs during optimization. With tests that verify your code produces correct results for known inputs, you can confidently run your test suite and know within seconds whether your optimizations broke anything.</p>"},{"location":"tests/#how","title":"How","text":"<p>The most popular testing framework for Python is <code>pytest</code>.</p>"},{"location":"tests/#installing-pytest","title":"Installing pytest","text":"<p>If <code>pytest</code> is listed in your <code>pyproject.toml</code> as a test dependency, you can install it with:</p> <pre><code>pip install -e .[tests]\n</code></pre> <p>This installs your package in editable mode (<code>-e</code>) along with the test dependencies.</p> <p>For the <code>dev-tutorial</code> package, <code>pytest</code> is already included in the <code>tests</code> optional dependencies:</p> <pre><code>[project.optional-dependencies]\ntests = [\n  \"pytest\",\n  \"pytest-regressions\"\n]\n</code></pre>"},{"location":"tests/#running-pytest","title":"Running pytest","text":"<p>To run all tests in your project with added verbosity (<code>-v</code>):</p> <pre><code>pytest -v\n</code></pre> <p>Pytest automatically discovers test files (files starting with <code>test_</code> or ending with <code>_test.py</code>) and runs all functions starting with <code>test_</code>.</p> <pre><code>========================================================= test session starts =========================================================\nplatform darwin -- Python 3.9.6, pytest-8.4.2, pluggy-1.6.0 -- /Users/mbercx/tmp/workshop/.my_env/bin/python3\ncachedir: .pytest_cache\nrootdir: /Users/mbercx/tmp/workshop/dev-tutorial\nconfigfile: pyproject.toml\nplugins: datadir-1.8.0, regressions-2.8.3\ncollected 2 items\n\ntests/test_functions.py::test_add PASSED                                                                                        [ 50%]\ntests/test_functions.py::test_fixture PASSED                                                                                    [100%]\n\n========================================================== 2 passed in 0.01s ==========================================================\n</code></pre> <p>Hopefully all the tests passed! If a test fails, <code>pytest</code> shows detailed information about what went wrong.</p>"},{"location":"tests/#writing-a-simple-test","title":"Writing a simple test","text":"<p>Tests go in the <code>tests/</code> directory. Here's a simple example testing the <code>add</code> function from <code>tests/test_functions.py</code>:</p> <pre><code># tests/test_functions.py\nfrom dev_tutorial_&lt;YOUR_USERNAME&gt;.functions import add\n\ndef test_add():\n    \"\"\"Test the `add` function.\"\"\"\n    assert add(2, 3) == 5\n    assert add(-1, 1) == 0\n    assert add(0, 0) == 0\n</code></pre> <p>The key elements:</p> <ul> <li>Function name starts with <code>test_</code>: This tells pytest it's a test.</li> <li><code>assert</code> statements: Check that conditions are true. If an assertion fails, the test fails.</li> <li>Multiple assertions: You can have multiple checks in one test.</li> <li>Docstring: Optional but recommended to describe what the test does.</li> </ul>"},{"location":"tests/#using-fixtures","title":"Using fixtures","text":"<p>Fixtures are reusable pieces of code that set up test conditions. They're defined in <code>conftest.py</code> and can be used across multiple test files.</p> <p>Here's the example from <code>dev-tutorial</code>:</p> <pre><code># tests/conftest.py\nimport pytest\n\n@pytest.fixture\ndef list_of_integers():\n    return [0, 1, 2, 3, 4]\n</code></pre> <pre><code># tests/test_functions.py\nfrom dev_tutorial_&lt;YOUR_USERNAME&gt;.functions import sum_and_multiply\n\ndef test_fixture(list_of_integers):\n    \"\"\"Test the `sum_and_multiply` function using the `list_of_integers` fixture.\"\"\"\n    assert sum_and_multiply(list_of_integers, 2) == 20\n</code></pre> <p>Fixtures are useful for setting up test data or any code you want to reuse across tests. To use a fixture, simply add it as a parameter to your test function. <code>pytest</code> automatically calls the fixture and passes the result to your test.</p> <p>In this example, <code>list_of_integers</code> returns <code>[0, 1, 2, 3, 4]</code>, which sums to 10. Multiplying by 2 gives 20, which is what the test verifies.</p>"},{"location":"tests/#writing-an-integration-test-with-pytest-regressions","title":"Writing an integration test with pytest-regressions","text":"<p>The <code>pytest-regressions</code> package provides fixtures for automatically comparing test outputs against stored reference data. This is especially useful for testing complex outputs like dictionaries, dataframes, or files.</p> <p>The <code>data_regression</code> fixture is particularly powerful for more complex data. Here's an example from <code>tests/test_functions.py</code>:</p> <pre><code># tests/test_functions.py\ndef test_data_regression(list_of_integers, data_regression):\n    result = multiply(list_of_integers, 2)\n    data_regression.check(result)\n</code></pre> <p>In the template package, the test is still commented. Remove the comment symbols (<code>#</code>) and run your tests again. The first time you run this test, it will fail with:</p> <pre><code>&gt;       data_regression.check(result)\nE       Failed: File not found in data directory, created:\nE       - /Users/mbercx/tmp/workshop/dev-tutorial/tests/test_functions/test_data_regression.yml\n</code></pre> <p>The <code>data_regression</code> fixture creates a file at <code>tests/test_functions/test_data_regression.yml</code> containing the reference output. On subsequent runs, it compares the current output against this reference.</p> <p>For the example above, the reference file would contain:</p> <pre><code>- 0\n- 2\n- 4\n- 6\n- 8\n</code></pre> <p>If the output changes:</p> <ul> <li>The test fails and shows you the difference</li> <li>Run <code>pytest --force-regen</code> to update the reference files if the changes are intentional</li> <li>You can review the changes to verify they're correct</li> </ul> <p>If you have some time, give it a try! Change the factor in the test from 2 to 3, and see what happens.</p> <p>Tips for writing good tests</p> <ul> <li>Test edge cases: Don't just test the happy path.   What happens with empty inputs? Very large numbers? Invalid data?</li> <li>Keep tests independent: Each test should work on its own, not depend on other tests running first.</li> <li>Use descriptive names: <code>test_add_handles_negative_numbers</code> is better than <code>test_add_2</code>.</li> </ul> <p>Your tests are keeping your code reliable! Now let's make your code look professional and catch potential bugs before they happen with automated formatting and linting. Next up: Formatting/linting your code with Ruff</p>"},{"location":"version_control/","title":"Version control","text":""},{"location":"version_control/#what","title":"What","text":"<p>A version control system (VCS) is a tool that tracks changes to a file or set of files over time so that you can recall specific versions later. There are many VCS out there, but the leading one is <code>git</code>. Unless you need to learn a specific VCS because your collaborators use it, I would stick with <code>git</code>.</p>"},{"location":"version_control/#why","title":"Why","text":"<p>Version control serves several critical purposes:</p> <p>History and recovery: Track every change made to your code, who made it, and when. If something breaks, you can identify exactly what changed and revert to a working version.</p> <p>Collaboration: Multiple people can work on the same codebase simultaneously without overwriting each other's changes. Git helps merge contributions and resolve conflicts.</p> <p>Code review: Changes can be reviewed before being merged into the main code, improving quality and knowledge sharing across the team.</p> <p>Real-world scenario</p> <p>Imagine you have a piece of working code, but want to make some changes. It's late, you're out of coffee, and after working for half an hour you realise that you've made several mistakes, and the code is completely broken. However, you've already saved your file with your changes, and you don't have a backup.</p> <ul> <li>How would you know what you have changed to the code?</li> <li>How would you go back to the version that worked?</li> </ul> <p>Running 'undo' repeatedly might work if you catch it immediately, but what if you closed the editor or worked across multiple files? You could spend hours reconstructing the code. With <code>git</code>, you can see exactly what changed with <code>git diff</code> and revert to the working version with a single command.</p> <p>Glossary</p> <p>We'll be using a lot of lingo in this workshop that you might not be familiar with. If you find yourself wondering what e.g. a version control system (VCS) is again, have a look at the glossary.</p>"},{"location":"version_control/#how","title":"How","text":"<p>Git is a massive beast, and learning how to use it properly is beyond the scope of this introduction. I would highly recommend that you simply sit down at some point and read the first three chapters of the Git book. Here, we'll simply show some basic <code>git</code> commands to get you up and running, and go through the rest of the workshop material.</p> <p>Start by creating an empty directory:</p> <pre><code>mkdir test-repo\ncd test-repo\n</code></pre> <p>To start tracking any changes made to files in this directory, run</p> <pre><code>git init\n</code></pre> <pre><code>Initialized empty Git repository in /path/to/your/softdev-workshop/test-repo/.git/\n</code></pre> <p>Great! Let's check our status:</p> <pre><code>git status\n</code></pre> <pre><code>On branch main\n\nNo commits yet\n\nnothing to commit (create/copy files and use \"git add\" to track)\n</code></pre> <p>We can see three pieces of information:</p> <ol> <li>We're working on the <code>main</code> branch.    Branches are a very important concept in <code>git</code>, and they get a whole chapter in the Git book.    We'll come back to why we use them later.</li> <li>There are no commits yet.    Commits are a snapshot of your codebase, but we haven't added any code yet!</li> <li>There is nothing to commit.    Again: we haven't added any code yet, so that makes sense.</li> </ol> <p>So let's add some code!</p> <pre><code>echo 'print(\"Hello world!\")' &gt; module.py\n</code></pre> <p>Let's check our status again with <code>git status</code>. We can see something has changed:</p> <pre><code>Untracked files:\n  (use \"git add &lt;file&gt;...\" to include in what will be committed)\n        module.py\n</code></pre> <p>The <code>module.py</code> file is now in the list of \"untracked\" files. By default, <code>git</code> will not track your changes; you need to tell it to do so! The message in brackets hints as to how:</p> <pre><code>git add module.py\n</code></pre> <p>It seems like nothing has happened, but running <code>git status</code> again:</p> <pre><code>Changes to be committed:\n  (use \"git rm --cached &lt;file&gt;...\" to unstage)\n        new file:   module.py\n</code></pre> <p>We can see that the <code>module.py</code> file is now a \"new file\" which is \"to be committed\". Time to do our first commit:</p> <pre><code>git commit -m 'Initial commit'\n</code></pre> <pre><code>[main (root-commit) 333f360] Initial commit\n 1 file changed, 1 insertion(+)\n create mode 100644 module.py\n</code></pre> <p>We have made our first commit on the <code>main</code> branch, i.e. the \"root commit\". Some more details:</p> <ul> <li><code>333f360</code> is the short form of the commit SHA (Secure Hash Algorithm).   It can be used to reference to commits with various <code>git</code> commands.</li> <li>Using the <code>-m, --message</code> option, we have specified a commit message (<code>Initial commit</code>).   A commit message can be used to explain the changes, and good commit messages are an essential component of good development practises.</li> <li>We've changed 1 file, where we added 1 line (insertion).</li> <li>Since it's a new file, <code>git</code> \"created\" it with mode <code>100644</code> (<code>100</code>: regular file; <code>644</code> = UNIX file permissions).</li> </ul> <p>What if we change the contents of the file? Let's add another line of code:</p> <pre><code>echo 'print(\"How are you?\")' &gt;&gt; module.py\n</code></pre> <p>Running <code>git status</code> again:</p> <pre><code>On branch main\nChanges not staged for commit:\n  (use \"git add &lt;file&gt;...\" to update what will be committed)\n  (use \"git restore &lt;file&gt;...\" to discard changes in working directory)\n        modified:   module.py\n\nno changes added to commit (use \"git add\" and/or \"git commit -a\")\n</code></pre> <p>We can now see that <code>git</code> noticed that we modified the <code>module.py</code> file. To see the changes we can use <code>git diff</code>:</p> <p><pre><code>git diff\n</code></pre> <pre><code>diff --git a/module.py b/module.py\nindex f1a1813..dd87b53 100644\n--- a/module.py\n+++ b/module.py\n@@ -1 +1,2 @@\n print(\"Hello world!\")\n+print(\"How are you?\")\n</code></pre></p> <p>Let's stage (<code>add</code>) and commit our changes:</p> <p><pre><code>git add module.py\ngit commit -m 'Add question'\n</code></pre> <pre><code>[main 49451af] Add question\n 1 file changed, 1 insertion(+)\n</code></pre></p> <p>Tip</p> <p>You may be wondering why you have to <code>git add</code> a file before committing its changes. In many cases, you might not want to commit all the changes you've made in the repository. However, you can use the <code>-a, --all</code> option to do this, e.g.:</p> <pre><code>git commit -a -m 'Add question'\n</code></pre> <p>Finally, let's have a look at the Git log:</p> <pre><code>git log\n</code></pre> <pre><code>commit 49451af53c90be75918eb86c41491ec452bf4dfa (HEAD -&gt; main)\nAuthor: Marnik Bercx &lt;mbercx@gmail.com&gt;\nDate:   Fri Nov 7 15:34:31 2025 +1000\n\n    Add question\n\ncommit 333f36023da1dbce96cdcb19b48ad52adca4c58a\nAuthor: Marnik Bercx &lt;mbercx@gmail.com&gt;\nDate:   Fri Nov 7 15:17:41 2025 +1000\n\n    Initial commit\n</code></pre> <p><code>git</code>/GitHub workshop at UQ</p> <p>At UQ, Ben Roberts also runs a workshop on using <code>git</code> and GitHub which goes into much more detail than this tutorial. If you're curious, have a look at the workshop material.</p> <p>Now that you understand version control basics, let's move on to managing Python dependencies and isolated workspaces. Next up: Python environments</p>"}]}